{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": ["# ðŸ§© Data Preprocessing Notebook\nThis notebook prepares multimodal data (audio, physiological, and static) for training the AI-assisted wearable model."]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "import os, json, numpy as np, librosa, tensorflow as tf",
    "\nfrom sklearn.preprocessing import StandardScaler",
    "\nSR = 16000; N_MELS = 128; SPEC_SHAPE = (128,128)",
    "\ndef make_mel_spectrogram(wav, sr=SR, n_mels=N_MELS, spec_shape=SPEC_SHAPE):",
    "\n    S = librosa.feature.melspectrogram(y=wav, sr=sr, n_mels=n_mels)",
    "\n    S_db = librosa.power_to_db(S, ref=np.max)",
    "\n    S_db = (S_db - S_db.mean()) / (S_db.std() + 1e-8)",
    "\n    out = np.zeros(spec_shape, dtype=np.float32)",
    "\n    out[:S_db.shape[0], :S_db.shape[1]] = S_db[:spec_shape[0], :spec_shape[1]]",
    "\n    return out",
    "\nprint('âœ… Ready: Add dataset paths and export TFRecords for model training.')"
   ]
  }
 ],
 "metadata": {"kernelspec": {"display_name": "Python 3", "language": "python", "name": "python3"}},
 "nbformat": 4,
 "nbformat_minor": 2
}